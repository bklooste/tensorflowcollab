{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "1-xor-composition.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNrWKqiQhqBQTAsJRJb+Rmq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bklooste/tensorflowcollab/blob/master/2_xor_composition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ycqb7vGCKppr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9f8b8743-905e-4745-a6ee-c6a464f5faea"
      },
      "source": [
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7y-CY1xBKdxu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = [[0, 0], [0, 1], [1, 0], [1, 1]]\n",
        "y = [0, 1, 1, 0]\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7K1dMLvLNQ8q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "226e7b7e-fd76-4ca8-f12c-87496ff3be04",
        "id": "_QboCm8pN9B2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# sgd cant do this with 1 node \n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "X = np.array(X)\n",
        "y = np.array(y)\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Dense(2, activation='relu'),\n",
        "])\n",
        "sgd = tf.keras.optimizers.SGD(learning_rate=0.1)\n",
        "model.compile(optimizer= sgd,\n",
        "              \n",
        "              loss='mean_squared_error',\n",
        "              metrics=['mean_squared_error'])\n",
        "model.fit(X, y, epochs=1000, verbose=0)\n",
        "_, acc = model.evaluate(X, y)\n",
        "print('acc = ' + str(acc))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r4/4 [==============================] - 0s 12ms/sample - loss: 0.3750 - mean_squared_error: 0.3750\n",
            "acc = 0.375\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "9db09b58-998c-4565-f21f-d23e56f67438",
        "id": "zTlgpXxbNRcL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "X = np.array(X)\n",
        "y = np.array(y)\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Dense(2, activation='tanh', input_shape=(2,)),\n",
        "  tf.keras.layers.Dense(1, activation='sigmoid'),\n",
        "])\n",
        "sgd = tf.keras.optimizers.SGD(learning_rate=0.1)\n",
        "model.compile(optimizer=sgd,\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "model.fit(X, y, batch_size = 4, epochs=10000, verbose=0)\n",
        "_, acc = model.evaluate(X, y)\n",
        "print(model.predict_proba(X))\n",
        "print(model.get_weights())\n",
        "\n",
        "print(model.predict(X,batch_size=4))\n",
        "print('acc = ' + str(acc))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r4/4 [==============================] - 0s 16ms/sample - loss: 0.0033 - accuracy: 1.0000\n",
            "[[0.00243234]\n",
            " [0.9956612 ]\n",
            " [0.99567515]\n",
            " [0.00208755]]\n",
            "[array([[-3.7026477, -3.6892176],\n",
            "       [ 3.5758057,  3.7998266]], dtype=float32), array([-1.7133756,  1.7762771], dtype=float32), array([[ 6.243073],\n",
            "       [-6.230563]], dtype=float32), array([5.7171516], dtype=float32)]\n",
            "[[0.00243234]\n",
            " [0.9956612 ]\n",
            " [0.99567515]\n",
            " [0.00208755]]\n",
            "acc = 1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BpWrVLPzeUHV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "22303759-7db9-4d0f-8846-6c5466287d33",
        "id": "q_Yc3cxReUp8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#adam much better but still 50-100 \n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "X = np.array(X)\n",
        "y = np.array(y)\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Dense(2, activation='tanh', input_shape=(2,)),\n",
        "  tf.keras.layers.Dense(1, activation='sigmoid'),\n",
        "])\n",
        "sgd = tf.keras.optimizers.Adam(learning_rate=0.1)\n",
        "model.compile(optimizer=sgd,\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "model.fit(X, y, batch_size = 4, epochs=100, verbose=1)\n",
        "_, acc = model.evaluate(X, y)\n",
        "print(model.predict_proba(X))\n",
        "print(model.get_weights())\n",
        "\n",
        "print(model.predict(X,batch_size=4))\n",
        "print('acc = ' + str(acc))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 4 samples\n",
            "Epoch 1/100\n",
            "4/4 [==============================] - 0s 57ms/sample - loss: 0.8468 - accuracy: 0.5000\n",
            "Epoch 2/100\n",
            "4/4 [==============================] - 0s 1ms/sample - loss: 0.7482 - accuracy: 0.2500\n",
            "Epoch 3/100\n",
            "4/4 [==============================] - 0s 1ms/sample - loss: 0.7183 - accuracy: 0.7500\n",
            "Epoch 4/100\n",
            "4/4 [==============================] - 0s 755us/sample - loss: 0.7290 - accuracy: 0.5000\n",
            "Epoch 5/100\n",
            "4/4 [==============================] - 0s 657us/sample - loss: 0.7374 - accuracy: 0.5000\n",
            "Epoch 6/100\n",
            "4/4 [==============================] - 0s 573us/sample - loss: 0.7316 - accuracy: 0.5000\n",
            "Epoch 7/100\n",
            "4/4 [==============================] - 0s 1ms/sample - loss: 0.7183 - accuracy: 0.5000\n",
            "Epoch 8/100\n",
            "4/4 [==============================] - 0s 670us/sample - loss: 0.7053 - accuracy: 0.5000\n",
            "Epoch 9/100\n",
            "4/4 [==============================] - 0s 856us/sample - loss: 0.6967 - accuracy: 0.2500\n",
            "Epoch 10/100\n",
            "4/4 [==============================] - 0s 754us/sample - loss: 0.6933 - accuracy: 0.5000\n",
            "Epoch 11/100\n",
            "4/4 [==============================] - 0s 792us/sample - loss: 0.6936 - accuracy: 0.5000\n",
            "Epoch 12/100\n",
            "4/4 [==============================] - 0s 698us/sample - loss: 0.6956 - accuracy: 0.7500\n",
            "Epoch 13/100\n",
            "4/4 [==============================] - 0s 708us/sample - loss: 0.6973 - accuracy: 0.5000\n",
            "Epoch 14/100\n",
            "4/4 [==============================] - 0s 673us/sample - loss: 0.6978 - accuracy: 0.5000\n",
            "Epoch 15/100\n",
            "4/4 [==============================] - 0s 745us/sample - loss: 0.6968 - accuracy: 0.5000\n",
            "Epoch 16/100\n",
            "4/4 [==============================] - 0s 714us/sample - loss: 0.6947 - accuracy: 0.5000\n",
            "Epoch 17/100\n",
            "4/4 [==============================] - 0s 702us/sample - loss: 0.6918 - accuracy: 0.5000\n",
            "Epoch 18/100\n",
            "4/4 [==============================] - 0s 702us/sample - loss: 0.6888 - accuracy: 0.7500\n",
            "Epoch 19/100\n",
            "4/4 [==============================] - 0s 667us/sample - loss: 0.6861 - accuracy: 0.7500\n",
            "Epoch 20/100\n",
            "4/4 [==============================] - 0s 673us/sample - loss: 0.6840 - accuracy: 0.5000\n",
            "Epoch 21/100\n",
            "4/4 [==============================] - 0s 672us/sample - loss: 0.6823 - accuracy: 0.5000\n",
            "Epoch 22/100\n",
            "4/4 [==============================] - 0s 660us/sample - loss: 0.6810 - accuracy: 0.7500\n",
            "Epoch 23/100\n",
            "4/4 [==============================] - 0s 1ms/sample - loss: 0.6798 - accuracy: 0.7500\n",
            "Epoch 24/100\n",
            "4/4 [==============================] - 0s 1ms/sample - loss: 0.6782 - accuracy: 0.7500\n",
            "Epoch 25/100\n",
            "4/4 [==============================] - 0s 602us/sample - loss: 0.6759 - accuracy: 0.7500\n",
            "Epoch 26/100\n",
            "4/4 [==============================] - 0s 736us/sample - loss: 0.6726 - accuracy: 0.7500\n",
            "Epoch 27/100\n",
            "4/4 [==============================] - 0s 748us/sample - loss: 0.6681 - accuracy: 0.7500\n",
            "Epoch 28/100\n",
            "4/4 [==============================] - 0s 725us/sample - loss: 0.6624 - accuracy: 0.7500\n",
            "Epoch 29/100\n",
            "4/4 [==============================] - 0s 1ms/sample - loss: 0.6556 - accuracy: 0.7500\n",
            "Epoch 30/100\n",
            "4/4 [==============================] - 0s 848us/sample - loss: 0.6478 - accuracy: 0.7500\n",
            "Epoch 31/100\n",
            "4/4 [==============================] - 0s 1ms/sample - loss: 0.6392 - accuracy: 0.7500\n",
            "Epoch 32/100\n",
            "4/4 [==============================] - 0s 995us/sample - loss: 0.6298 - accuracy: 0.7500\n",
            "Epoch 33/100\n",
            "4/4 [==============================] - 0s 851us/sample - loss: 0.6195 - accuracy: 0.5000\n",
            "Epoch 34/100\n",
            "4/4 [==============================] - 0s 824us/sample - loss: 0.6084 - accuracy: 0.5000\n",
            "Epoch 35/100\n",
            "4/4 [==============================] - 0s 801us/sample - loss: 0.5962 - accuracy: 0.5000\n",
            "Epoch 36/100\n",
            "4/4 [==============================] - 0s 816us/sample - loss: 0.5829 - accuracy: 0.5000\n",
            "Epoch 37/100\n",
            "4/4 [==============================] - 0s 687us/sample - loss: 0.5688 - accuracy: 0.5000\n",
            "Epoch 38/100\n",
            "4/4 [==============================] - 0s 640us/sample - loss: 0.5538 - accuracy: 0.5000\n",
            "Epoch 39/100\n",
            "4/4 [==============================] - 0s 979us/sample - loss: 0.5383 - accuracy: 0.5000\n",
            "Epoch 40/100\n",
            "4/4 [==============================] - 0s 978us/sample - loss: 0.5226 - accuracy: 0.5000\n",
            "Epoch 41/100\n",
            "4/4 [==============================] - 0s 1ms/sample - loss: 0.5070 - accuracy: 0.7500\n",
            "Epoch 42/100\n",
            "4/4 [==============================] - 0s 589us/sample - loss: 0.4918 - accuracy: 0.7500\n",
            "Epoch 43/100\n",
            "4/4 [==============================] - 0s 781us/sample - loss: 0.4774 - accuracy: 0.7500\n",
            "Epoch 44/100\n",
            "4/4 [==============================] - 0s 815us/sample - loss: 0.4639 - accuracy: 0.7500\n",
            "Epoch 45/100\n",
            "4/4 [==============================] - 0s 914us/sample - loss: 0.4513 - accuracy: 0.7500\n",
            "Epoch 46/100\n",
            "4/4 [==============================] - 0s 788us/sample - loss: 0.4399 - accuracy: 0.7500\n",
            "Epoch 47/100\n",
            "4/4 [==============================] - 0s 721us/sample - loss: 0.4295 - accuracy: 0.7500\n",
            "Epoch 48/100\n",
            "4/4 [==============================] - 0s 693us/sample - loss: 0.4202 - accuracy: 0.7500\n",
            "Epoch 49/100\n",
            "4/4 [==============================] - 0s 1ms/sample - loss: 0.4118 - accuracy: 0.7500\n",
            "Epoch 50/100\n",
            "4/4 [==============================] - 0s 966us/sample - loss: 0.4045 - accuracy: 0.5000\n",
            "Epoch 51/100\n",
            "4/4 [==============================] - 0s 913us/sample - loss: 0.3980 - accuracy: 0.5000\n",
            "Epoch 52/100\n",
            "4/4 [==============================] - 0s 816us/sample - loss: 0.3924 - accuracy: 0.5000\n",
            "Epoch 53/100\n",
            "4/4 [==============================] - 0s 1ms/sample - loss: 0.3874 - accuracy: 0.5000\n",
            "Epoch 54/100\n",
            "4/4 [==============================] - 0s 935us/sample - loss: 0.3832 - accuracy: 0.5000\n",
            "Epoch 55/100\n",
            "4/4 [==============================] - 0s 1ms/sample - loss: 0.3794 - accuracy: 0.5000\n",
            "Epoch 56/100\n",
            "4/4 [==============================] - 0s 1ms/sample - loss: 0.3761 - accuracy: 0.5000\n",
            "Epoch 57/100\n",
            "4/4 [==============================] - 0s 966us/sample - loss: 0.3732 - accuracy: 0.5000\n",
            "Epoch 58/100\n",
            "4/4 [==============================] - 0s 1ms/sample - loss: 0.3706 - accuracy: 0.5000\n",
            "Epoch 59/100\n",
            "4/4 [==============================] - 0s 974us/sample - loss: 0.3683 - accuracy: 0.5000\n",
            "Epoch 60/100\n",
            "4/4 [==============================] - 0s 1ms/sample - loss: 0.3663 - accuracy: 0.5000\n",
            "Epoch 61/100\n",
            "4/4 [==============================] - 0s 1ms/sample - loss: 0.3646 - accuracy: 0.5000\n",
            "Epoch 62/100\n",
            "4/4 [==============================] - 0s 812us/sample - loss: 0.3632 - accuracy: 0.5000\n",
            "Epoch 63/100\n",
            "4/4 [==============================] - 0s 739us/sample - loss: 0.3619 - accuracy: 0.7500\n",
            "Epoch 64/100\n",
            "4/4 [==============================] - 0s 731us/sample - loss: 0.3608 - accuracy: 0.7500\n",
            "Epoch 65/100\n",
            "4/4 [==============================] - 0s 784us/sample - loss: 0.3598 - accuracy: 0.7500\n",
            "Epoch 66/100\n",
            "4/4 [==============================] - 0s 754us/sample - loss: 0.3589 - accuracy: 0.7500\n",
            "Epoch 67/100\n",
            "4/4 [==============================] - 0s 981us/sample - loss: 0.3581 - accuracy: 0.7500\n",
            "Epoch 68/100\n",
            "4/4 [==============================] - 0s 670us/sample - loss: 0.3574 - accuracy: 0.7500\n",
            "Epoch 69/100\n",
            "4/4 [==============================] - 0s 971us/sample - loss: 0.3568 - accuracy: 0.5000\n",
            "Epoch 70/100\n",
            "4/4 [==============================] - 0s 927us/sample - loss: 0.3562 - accuracy: 0.5000\n",
            "Epoch 71/100\n",
            "4/4 [==============================] - 0s 824us/sample - loss: 0.3557 - accuracy: 0.5000\n",
            "Epoch 72/100\n",
            "4/4 [==============================] - 0s 751us/sample - loss: 0.3553 - accuracy: 0.5000\n",
            "Epoch 73/100\n",
            "4/4 [==============================] - 0s 819us/sample - loss: 0.3549 - accuracy: 0.5000\n",
            "Epoch 74/100\n",
            "4/4 [==============================] - 0s 835us/sample - loss: 0.3545 - accuracy: 0.7500\n",
            "Epoch 75/100\n",
            "4/4 [==============================] - 0s 824us/sample - loss: 0.3542 - accuracy: 0.7500\n",
            "Epoch 76/100\n",
            "4/4 [==============================] - 0s 846us/sample - loss: 0.3539 - accuracy: 0.5000\n",
            "Epoch 77/100\n",
            "4/4 [==============================] - 0s 857us/sample - loss: 0.3536 - accuracy: 0.5000\n",
            "Epoch 78/100\n",
            "4/4 [==============================] - 0s 768us/sample - loss: 0.3533 - accuracy: 0.5000\n",
            "Epoch 79/100\n",
            "4/4 [==============================] - 0s 729us/sample - loss: 0.3531 - accuracy: 0.5000\n",
            "Epoch 80/100\n",
            "4/4 [==============================] - 0s 786us/sample - loss: 0.3528 - accuracy: 0.7500\n",
            "Epoch 81/100\n",
            "4/4 [==============================] - 0s 767us/sample - loss: 0.3527 - accuracy: 0.7500\n",
            "Epoch 82/100\n",
            "4/4 [==============================] - 0s 777us/sample - loss: 0.3525 - accuracy: 0.7500\n",
            "Epoch 83/100\n",
            "4/4 [==============================] - 0s 680us/sample - loss: 0.3523 - accuracy: 0.7500\n",
            "Epoch 84/100\n",
            "4/4 [==============================] - 0s 777us/sample - loss: 0.3521 - accuracy: 0.7500\n",
            "Epoch 85/100\n",
            "4/4 [==============================] - 0s 820us/sample - loss: 0.3520 - accuracy: 0.7500\n",
            "Epoch 86/100\n",
            "4/4 [==============================] - 0s 753us/sample - loss: 0.3518 - accuracy: 0.5000\n",
            "Epoch 87/100\n",
            "4/4 [==============================] - 0s 944us/sample - loss: 0.3517 - accuracy: 0.5000\n",
            "Epoch 88/100\n",
            "4/4 [==============================] - 0s 719us/sample - loss: 0.3516 - accuracy: 0.5000\n",
            "Epoch 89/100\n",
            "4/4 [==============================] - 0s 846us/sample - loss: 0.3515 - accuracy: 0.5000\n",
            "Epoch 90/100\n",
            "4/4 [==============================] - 0s 769us/sample - loss: 0.3514 - accuracy: 0.5000\n",
            "Epoch 91/100\n",
            "4/4 [==============================] - 0s 700us/sample - loss: 0.3513 - accuracy: 0.5000\n",
            "Epoch 92/100\n",
            "4/4 [==============================] - 0s 637us/sample - loss: 0.3512 - accuracy: 0.5000\n",
            "Epoch 93/100\n",
            "4/4 [==============================] - 0s 712us/sample - loss: 0.3511 - accuracy: 0.5000\n",
            "Epoch 94/100\n",
            "4/4 [==============================] - 0s 810us/sample - loss: 0.3510 - accuracy: 0.5000\n",
            "Epoch 95/100\n",
            "4/4 [==============================] - 0s 889us/sample - loss: 0.3509 - accuracy: 0.5000\n",
            "Epoch 96/100\n",
            "4/4 [==============================] - 0s 853us/sample - loss: 0.3508 - accuracy: 0.5000\n",
            "Epoch 97/100\n",
            "4/4 [==============================] - 0s 923us/sample - loss: 0.3507 - accuracy: 0.5000\n",
            "Epoch 98/100\n",
            "4/4 [==============================] - 0s 838us/sample - loss: 0.3507 - accuracy: 0.7500\n",
            "Epoch 99/100\n",
            "4/4 [==============================] - 0s 1ms/sample - loss: 0.3506 - accuracy: 0.7500\n",
            "Epoch 100/100\n",
            "4/4 [==============================] - 0s 911us/sample - loss: 0.3505 - accuracy: 0.7500\n",
            "4/4 [==============================] - 0s 20ms/sample - loss: 0.3505 - accuracy: 0.7500\n",
            "[[0.00357584]\n",
            " [0.50001055]\n",
            " [0.99503917]\n",
            " [0.50347954]]\n",
            "[array([[ 2.9737058,  1.7504339],\n",
            "       [ 4.2170014, -4.1287737]], dtype=float32), array([-0.6874598, -1.0328382], dtype=float32), array([[3.9999752],\n",
            "       [3.3281348]], dtype=float32), array([-0.66514635], dtype=float32)]\n",
            "[[0.00357584]\n",
            " [0.50001055]\n",
            " [0.99503917]\n",
            " [0.50347954]]\n",
            "acc = 0.75\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N5FmQi2ghYCW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "d75a09e8-1327-4218-8082-0080281a5080"
      },
      "source": [
        "#try win man \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def count(x):\n",
        "    return  np.count_nonzero(x)\n",
        "\n",
        "\n",
        "model = tf.keras.models.Sequential([     \n",
        "                                    # (lambda x: x * scale)                              \n",
        "  tf.keras.layers.Lambda(count),\n",
        "#  tf.keras.layers.Dense(2, activation='tanh', input_shape=(2,)),\n",
        "  tf.keras.layers.Dense(1, activation='sigmoid'),\n",
        "])\n",
        "sgd = tf.keras.optimizers.Adam(learning_rate=0.1)\n",
        "model.compile(optimizer=sgd,\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "model.fit(X, y, batch_size = 4, epochs=100, verbose=1)\n",
        "_, acc = model.evaluate(X, y)\n",
        "print(model.predict_proba(X))\n",
        "print(model.get_weights())\n",
        "\n",
        "print(model.predict(X,batch_size=4))\n",
        "print('acc = ' + str(acc))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-b8f25df8a4b9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m               \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'binary_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m               metrics=['accuracy'])\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m   def evaluate(self,\n",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    233\u001b[0m           \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m           \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 235\u001b[0;31m           use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m       \u001b[0mtotal_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_total_number_of_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_data_adapter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36m_process_training_inputs\u001b[0;34m(model, x, y, batch_size, epochs, sample_weights, class_weights, steps_per_epoch, validation_split, validation_data, validation_steps, shuffle, distribution_strategy, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    591\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 593\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    594\u001b[0m     \u001b[0mval_adapter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36m_process_inputs\u001b[0;34m(model, mode, x, y, batch_size, epochs, sample_weights, class_weights, shuffle, steps, distribution_strategy, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    644\u001b[0m     \u001b[0mstandardize_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    645\u001b[0m     x, y, sample_weights = standardize(\n\u001b[0;32m--> 646\u001b[0;31m         x, y, sample_weight=sample_weights)\n\u001b[0m\u001b[1;32m    647\u001b[0m   \u001b[0;32melif\u001b[0m \u001b[0madapter_cls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mdata_adapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mListsOfScalarsDataAdapter\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    648\u001b[0m     \u001b[0mstandardize_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstandardize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle, extract_tensors_from_dataset)\u001b[0m\n\u001b[1;32m   2358\u001b[0m     \u001b[0mis_compile_called\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2359\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_compiled\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2360\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compile_from_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2361\u001b[0m       \u001b[0mis_compile_called\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2362\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_compile_from_inputs\u001b[0;34m(self, all_inputs, target, orig_inputs, orig_target)\u001b[0m\n\u001b[1;32m   2616\u001b[0m         \u001b[0msample_weight_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_weight_mode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2617\u001b[0m         \u001b[0mrun_eagerly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_eagerly\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2618\u001b[0;31m         experimental_run_tf_function=self._experimental_run_tf_function)\n\u001b[0m\u001b[1;32m   2619\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2620\u001b[0m   \u001b[0;31m# TODO(omalleyt): Consider changing to a more descriptive function name.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    455\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mcompile\u001b[0;34m(self, optimizer, loss, metrics, loss_weights, sample_weight_mode, weighted_metrics, target_tensors, distribute, **kwargs)\u001b[0m\n\u001b[1;32m    414\u001b[0m                           self.loss_functions, target_tensors):\n\u001b[1;32m    415\u001b[0m       \u001b[0mendpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_TrainingEndpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 416\u001b[0;31m       \u001b[0mendpoint\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_training_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_eagerly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_eagerly\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    417\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_training_endpoints\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mendpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mcreate_training_target\u001b[0;34m(self, target, run_eagerly)\u001b[0m\n\u001b[1;32m   3021\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3022\u001b[0m         target_dtype = losses.LABEL_DTYPES_FOR_LOSSES.get(\n\u001b[0;32m-> 3023\u001b[0;31m             self.loss_fn, K.dtype(self.output))\n\u001b[0m\u001b[1;32m   3024\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3025\u001b[0m         target = K.placeholder(\n",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36mdtype\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   1235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1236\u001b[0m   \"\"\"\n\u001b[0;32m-> 1237\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_dtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'dtype'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gq_00mdoeVUI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NnG_P4pahcFJ",
        "colab": {}
      },
      "source": [
        "#what we do here is a tf.function so a human programmer can add value and compose . \n",
        "# tensorflow does most of thew heavy lifting \n",
        "\n",
        "# a human being knows here that the number of 0s and 1s in the input are important "
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}