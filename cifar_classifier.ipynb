{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cifar-classifier.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bklooste/tensorflowcollab/blob/master/cifar_classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "5XHBpCexS5BU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Imports"
      ]
    },
    {
      "metadata": {
        "id": "z0DRPKl39290",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pickle\n",
        "import os\n",
        "import urllib\n",
        "import zipfile \n",
        "import tarfile\n",
        "from six.moves import urllib\n",
        "\n",
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "# tensorflow imports\n",
        "import tensorflow as tf\n",
        "from tensorflow.contrib.training import HParams\n",
        "\n",
        "# tf.keras imports\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.layers import Dense, Conv2D, Activation, Flatten\n",
        "from tensorflow.keras.layers import BatchNormalization, AveragePooling2D, Input\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# import for showing the confusion matrix\n",
        "import itertools\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EJJ9RthRS9Fv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Define hyperparameters for training"
      ]
    },
    {
      "metadata": {
        "id": "KZtezQ4qD-lU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "hparams = HParams(\n",
        "    n_classes=10,  # number of different classes in dataset\n",
        "    learning_rate=1e-4,  # fixed learning rate\n",
        "    train_batch_size=32,  # training batch size\n",
        "    val_batch_size=32,  # validation batch size\n",
        "    test_batch_size=32,  # testing batch size\n",
        "    n_epochs=10,  # number of epochs to train\n",
        "    input_name='input_1',  # name of the input tensor for first layer of Keras model\n",
        "    data_dir='/tmp/cifar-data/',  # path to data directory\n",
        "    checkpoint_dir='/tmp/checkpoints/'  # path to model checkpoint directory\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BsL72f44TA3I",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Monitor training using TensorBoard"
      ]
    },
    {
      "metadata": {
        "id": "BXSBbyK1FyBh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "First, let's download and install the awesome tool [ngrok](https://ngrok.com/). Ngrok allows us to create a public URL to access the localhost of the ipython environment within Google Colab. This allows us to access the TensorBoard within the browser of your local machine."
      ]
    },
    {
      "metadata": {
        "id": "L35DdtT_FOXP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "! wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
        "! unzip -o ngrok-stable-linux-amd64.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EB5P9HvKEblD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now, we run `ngrok` in the `ipython` environment and tunnel the data to a public random URL using ngrok."
      ]
    },
    {
      "metadata": {
        "id": "YwZrIjZkEEYu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# kill all running ngrok instances\n",
        "!pkill -f ngrok\n",
        "\n",
        "# Execute tensorboard\n",
        "!rm rf /tmp/checkpoints\n",
        "!mkdir /tmp/checkpoints\n",
        "LOG_DIR = '/tmp/checkpoints/'\n",
        "get_ipython().system_raw(\n",
        "    'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n",
        "    .format(LOG_DIR)\n",
        ")\n",
        "\n",
        "# execute ngrok\n",
        "get_ipython().system_raw('./ngrok http 6006 &')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gkCnSnAREdny",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The below code should output a URL containg the TensorBoard visualizations for the classifier we are about to train and evaluate."
      ]
    },
    {
      "metadata": {
        "id": "3Imio4YREFzg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Do the tunneling\n",
        "! curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
        "    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0KqmhIDXTKK7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Data download and preprocessing"
      ]
    },
    {
      "metadata": {
        "id": "VuC2mMKOIIRJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "This code is boilerplate code for downloading and preprocessing of the CIFAR-10 dataset. Credits to [Hvass-Labs](https://github.com/Hvass-Labs/TensorFlow-Tutorials/blob/master/cifar10.py)."
      ]
    },
    {
      "metadata": {
        "id": "2EpQ-iJN94G1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# URL for the data-set on the internet.\n",
        "data_url = \"https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\"\n",
        "\n",
        "# Width and height of each image.\n",
        "img_size = 32\n",
        "\n",
        "# Number of channels in each image, 3 channels: Red, Green, Blue.\n",
        "num_channels = 3\n",
        "\n",
        "# Length of an image when flattened to a 1-dim array.\n",
        "img_size_flat = img_size * img_size * num_channels\n",
        "\n",
        "# Number of classes.\n",
        "num_classes = hparams.n_classes\n",
        "\n",
        "########################################################################\n",
        "# Various constants used to allocate arrays of the correct size.\n",
        "\n",
        "# Number of files for the training-set.\n",
        "_num_files_train = 5\n",
        "\n",
        "# Number of images for each batch-file in the training-set.\n",
        "_images_per_file = 10000\n",
        "\n",
        "# Total number of images in the training-set.\n",
        "# This is used to pre-allocate arrays for efficiency.\n",
        "_num_images_train = _num_files_train * _images_per_file\n",
        "\n",
        "########################################################################\n",
        "# Private functions for downloading, unpacking and loading data-files.\n",
        "\n",
        "\n",
        "def download(base_url, filename, download_dir):\n",
        "    \"\"\"\n",
        "    Download the given file if it does not already exist in the download_dir.\n",
        "    :param base_url: The internet URL without the filename.\n",
        "    :param filename: The filename that will be added to the base_url.\n",
        "    :param download_dir: Local directory for storing the file.\n",
        "    :return: Nothing.\n",
        "    \"\"\"\n",
        "\n",
        "    # Path for local file.\n",
        "    save_path = os.path.join(download_dir, filename)\n",
        "\n",
        "    # Check if the file already exists, otherwise we need to download it now.\n",
        "    if not os.path.exists(save_path):\n",
        "        # Check if the download directory exists, otherwise create it.\n",
        "        if not os.path.exists(download_dir):\n",
        "            os.makedirs(download_dir)\n",
        "\n",
        "        print(\"Downloading\", filename, \"...\")\n",
        "\n",
        "        # Download the file from the internet.\n",
        "        url = base_url + filename\n",
        "        file_path, _ = urllib.request.urlretrieve(url=url,\n",
        "                                                  filename=save_path)\n",
        "\n",
        "        print(\" Done!\")\n",
        "\n",
        "\n",
        "def maybe_download_and_extract(url=data_url, download_dir=hparams.data_dir):\n",
        "    \"\"\"\n",
        "    Download and extract the data if it doesn't already exist.\n",
        "    Assumes the url is a tar-ball file.\n",
        "    :param url:\n",
        "        Internet URL for the tar-file to download.\n",
        "        Example: \"https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\"\n",
        "    :param download_dir:\n",
        "        Directory where the downloaded file is saved.\n",
        "        Example: \"data/CIFAR-10/\"\n",
        "    :return:\n",
        "        Nothing.\n",
        "    \"\"\"\n",
        "\n",
        "    # Filename for saving the file downloaded from the internet.\n",
        "    # Use the filename from the URL and add it to the download_dir.\n",
        "    filename = url.split('/')[-1]\n",
        "    file_path = os.path.join(download_dir, filename)\n",
        "\n",
        "    # Check if the file already exists.\n",
        "    # If it exists then we assume it has also been extracted,\n",
        "    # otherwise we need to download and extract it now.\n",
        "    if not os.path.exists(file_path):\n",
        "        # Check if the download directory exists, otherwise create it.\n",
        "        if not os.path.exists(download_dir):\n",
        "            os.makedirs(download_dir)\n",
        "\n",
        "        # Download the file from the internet.\n",
        "        file_path, _ = urllib.request.urlretrieve(url=url,\n",
        "                                                  filename=file_path)\n",
        "\n",
        "        print()\n",
        "        print(\"Download finished. Extracting files.\")\n",
        "\n",
        "        if file_path.endswith(\".zip\"):\n",
        "            # Unpack the zip-file.\n",
        "            zipfile.ZipFile(file=file_path, mode=\"r\").extractall(download_dir)\n",
        "        elif file_path.endswith((\".tar.gz\", \".tgz\")):\n",
        "            # Unpack the tar-ball.\n",
        "            tarfile.open(name=file_path, mode=\"r:gz\").extractall(download_dir)\n",
        "\n",
        "        print(\"Done.\")\n",
        "    else:\n",
        "        print(\"Data has apparently already been downloaded and unpacked.\")\n",
        "\n",
        "\n",
        "def _get_file_path(filename=\"\"):\n",
        "    \"\"\"\n",
        "    Return the full path of a data-file for the data-set.\n",
        "\n",
        "    If filename==\"\" then return the directory of the files.\n",
        "    \"\"\"\n",
        "\n",
        "    return os.path.join(hparams.data_dir, \"cifar-10-batches-py/\", filename)\n",
        "\n",
        "\n",
        "def _unpickle(filename):\n",
        "    \"\"\"\n",
        "    Unpickle the given file and return the data.\n",
        "\n",
        "    Note that the appropriate dir-name is prepended the filename.\n",
        "    \"\"\"\n",
        "\n",
        "    # Create full path for the file.\n",
        "    file_path = _get_file_path(filename)\n",
        "\n",
        "    print(\"Loading data: \" + file_path)\n",
        "\n",
        "    with open(file_path, mode='rb') as file:\n",
        "        # In Python 3.X it is important to set the encoding,\n",
        "        # otherwise an exception is raised here.\n",
        "        data = pickle.load(file,encoding='bytes')\n",
        "\n",
        "    return data\n",
        "\n",
        "\n",
        "def _convert_images(raw):\n",
        "    \"\"\"\n",
        "    Convert images from the CIFAR-10 format and\n",
        "    return a 4-dim array with shape: [image_number, height, width, channel]\n",
        "    where the pixels are floats between 0.0 and 1.0.\n",
        "    \"\"\"\n",
        "\n",
        "    # Convert the raw images from the data-files to floating-points.\n",
        "    raw_float = np.array(raw, dtype=float) / 255.0\n",
        "\n",
        "    # Reshape the array to 4-dimensions.\n",
        "    images = raw_float.reshape([-1, num_channels, img_size, img_size])\n",
        "\n",
        "    # Reorder the indices of the array.\n",
        "    images = images.transpose([0, 2, 3, 1])\n",
        "\n",
        "    return images\n",
        "\n",
        "\n",
        "def _load_data(filename):\n",
        "    \"\"\"\n",
        "    Load a pickled data-file from the CIFAR-10 data-set\n",
        "    and return the converted images (see above) and the class-number\n",
        "    for each image.\n",
        "    \"\"\"\n",
        "\n",
        "    # Load the pickled data-file.\n",
        "    data = _unpickle(filename)\n",
        "\n",
        "    # Get the raw images.\n",
        "    raw_images = data[b'data']\n",
        "\n",
        "    # Get the class-numbers for each image. Convert to numpy-array.\n",
        "    cls = np.array(data[b'labels'])\n",
        "\n",
        "    # Convert the images.\n",
        "    images = _convert_images(raw_images)\n",
        "\n",
        "    return images, cls\n",
        "\n",
        "\n",
        "def load_class_names():\n",
        "    # Load the class-names from the pickled file.\n",
        "    raw = _unpickle(filename=\"batches.meta\")[b'label_names']\n",
        "\n",
        "    # Convert from binary strings.\n",
        "    names = [x.decode('utf-8') for x in raw]\n",
        "\n",
        "    return names\n",
        "\n",
        "\n",
        "def load_training_data():\n",
        "    \"\"\"\n",
        "    Load all the training-data for the CIFAR-10 data-set.\n",
        "\n",
        "    The data-set is split into 5 data-files which are merged here.\n",
        "\n",
        "    Returns the images, class-numbers and one-hot encoded class-labels.\n",
        "    \"\"\"\n",
        "\n",
        "    # Pre-allocate the arrays for the images and class-numbers for efficiency.\n",
        "    images = np.zeros(shape=[_num_images_train, img_size, img_size, num_channels], dtype=float)\n",
        "    cls = np.zeros(shape=[_num_images_train], dtype=int)\n",
        "\n",
        "    # Begin-index for the current batch.\n",
        "    begin = 0\n",
        "\n",
        "    # For each data-file.\n",
        "    for i in range(_num_files_train):\n",
        "        # Load the images and class-numbers from the data-file.\n",
        "        images_batch, cls_batch = _load_data(filename=\"data_batch_\" + str(i + 1))\n",
        "\n",
        "        # Number of images in this batch.\n",
        "        num_images = len(images_batch)\n",
        "\n",
        "        # End-index for the current batch.\n",
        "        end = begin + num_images\n",
        "\n",
        "        # Store the images into the array.\n",
        "        images[begin:end, :] = images_batch\n",
        "\n",
        "        # Store the class-numbers into the array.\n",
        "        cls[begin:end] = cls_batch\n",
        "\n",
        "        # The begin-index for the next batch is the current end-index.\n",
        "        begin = end\n",
        "\n",
        "    return images, cls\n",
        "\n",
        "\n",
        "def load_validation_data():\n",
        "\n",
        "    images, cls = _load_data(filename=\"test_batch\")\n",
        "\n",
        "    images = images[5000:, :, :, :]\n",
        "    cls = cls[5000:]\n",
        "\n",
        "    return images, cls\n",
        "\n",
        "def load_testing_data():\n",
        "\n",
        "\n",
        "    images, cls = _load_data(filename=\"test_batch\")\n",
        "\n",
        "    images = images[:5000, :, :, :]\n",
        "    cls = cls[:5000]\n",
        "\n",
        "    return images, cls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eiCehG29Urjk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Network architecture\n",
        "\n",
        "The below code defines the architecture of the neural network we are going to train. We will be using the infamous Resnet architecture with Shortcut connections and bottlenecs. The paper may be found [here](https://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/He_Deep_Residual_Learning_CVPR_2016_paper.pdf).\n",
        "\n",
        "We will be using the `tensorflow.keras` API - TensorFlow's implementation of the Keras API specification. This is a high-level API to build and train models that includes first-class support for TensorFlow-specific functionality. Keras is able to use TensorFlow as its backend for tensor processing during training and inference, making Keras easy-to-use but also just as fast as pure TensorFlow models.\n",
        "\n",
        "The model code is part of the Keras examples and may be found [here](https://github.com/keras-team/keras/blob/master/examples/cifar10_resnet.py)."
      ]
    },
    {
      "metadata": {
        "id": "9mj6sUIhU009",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def resnet_layer(inputs,\n",
        "                 num_filters=16,\n",
        "                 kernel_size=3,\n",
        "                 strides=1,\n",
        "                 activation='relu',\n",
        "                 batch_normalization=True,\n",
        "                 conv_first=True):\n",
        "    \"\"\"2D Convolution-Batch Normalization-Activation stack builder\n",
        "    # Arguments\n",
        "        inputs (tensor): input tensor from input image or previous layer\n",
        "        num_filters (int): Conv2D number of filters\n",
        "        kernel_size (int): Conv2D square kernel dimensions\n",
        "        strides (int): Conv2D square stride dimensions\n",
        "        activation (string): activation name\n",
        "        batch_normalization (bool): whether to include batch normalization\n",
        "        conv_first (bool): conv-bn-activation (True) or\n",
        "            bn-activation-conv (False)\n",
        "    # Returns\n",
        "        x (tensor): tensor as input to the next layer\n",
        "    \"\"\"\n",
        "    conv = Conv2D(num_filters,\n",
        "                  kernel_size=kernel_size,\n",
        "                  strides=strides,\n",
        "                  padding='same',\n",
        "                  kernel_initializer='he_normal',\n",
        "                  kernel_regularizer=tf.keras.regularizers.l2(1e-4))\n",
        "\n",
        "    x = inputs\n",
        "    if conv_first:\n",
        "        x = conv(x)\n",
        "        if batch_normalization:\n",
        "            x = BatchNormalization()(x)\n",
        "        if activation is not None:\n",
        "            x = Activation(activation)(x)\n",
        "    else:\n",
        "        if batch_normalization:\n",
        "            x = BatchNormalization()(x)\n",
        "        if activation is not None:\n",
        "            x = Activation(activation)(x)\n",
        "        x = conv(x)\n",
        "    return x\n",
        "\n",
        "\n",
        "def resnet_v2(input_shape, batch_size=1024,depth=20, num_classes=10):\n",
        "    \"\"\"ResNet Version 2 Model builder [b]\n",
        "    Stacks of (1 x 1)-(3 x 3)-(1 x 1) BN-ReLU-Conv2D or also known as\n",
        "    bottleneck layer\n",
        "    First shortcut connection per layer is 1 x 1 Conv2D.\n",
        "    Second and onwards shortcut connection is identity.\n",
        "    At the beginning of each stage, the feature map size is halved (downsampled)\n",
        "    by a convolutional layer with strides=2, while the number of filter maps is\n",
        "    doubled. Within each stage, the layers have the same number filters and the\n",
        "    same filter map sizes.\n",
        "    Features maps sizes:\n",
        "    conv1  : 32x32,  16\n",
        "    stage 0: 32x32,  64\n",
        "    stage 1: 16x16, 128\n",
        "    stage 2:  8x8,  256\n",
        "    # Arguments\n",
        "        input_shape (tensor): shape of input image tensor\n",
        "        depth (int): number of core convolutional layers\n",
        "        num_classes (int): number of classes (CIFAR10 has 10)\n",
        "    # Returns\n",
        "        model (Model): Keras model instance\n",
        "    \"\"\"\n",
        "    if (depth - 2) % 9 != 0:\n",
        "        raise ValueError('depth should be 9n+2 (eg 56 or 110 in [b])')\n",
        "    # Start model definition.\n",
        "    num_filters_in = 16\n",
        "    num_res_blocks = int((depth - 2) / 9)\n",
        "\n",
        "    inputs = Input(shape=input_shape,\n",
        "                   batch_size=batch_size)\n",
        "    # v2 performs Conv2D with BN-ReLU on input before splitting into 2 paths\n",
        "    x = resnet_layer(inputs=inputs,\n",
        "                     num_filters=num_filters_in,\n",
        "                     conv_first=True)\n",
        "\n",
        "    # Instantiate the stack of residual units\n",
        "    for stage in range(3):\n",
        "        for res_block in range(num_res_blocks):\n",
        "            activation = 'relu'\n",
        "            batch_normalization = True\n",
        "            strides = 1\n",
        "            if stage == 0:\n",
        "                num_filters_out = num_filters_in * 4\n",
        "                if res_block == 0:  # first layer and first stage\n",
        "                    activation = None\n",
        "                    batch_normalization = False\n",
        "            else:\n",
        "                num_filters_out = num_filters_in * 2\n",
        "                if res_block == 0:  # first layer but not first stage\n",
        "                    strides = 2    # downsample\n",
        "\n",
        "            # bottleneck residual unit\n",
        "            y = resnet_layer(inputs=x,\n",
        "                             num_filters=num_filters_in,\n",
        "                             kernel_size=1,\n",
        "                             strides=strides,\n",
        "                             activation=activation,\n",
        "                             batch_normalization=batch_normalization,\n",
        "                             conv_first=False)\n",
        "            y = resnet_layer(inputs=y,\n",
        "                             num_filters=num_filters_in,\n",
        "                             conv_first=False)\n",
        "            y = resnet_layer(inputs=y,\n",
        "                             num_filters=num_filters_out,\n",
        "                             kernel_size=1,\n",
        "                             conv_first=False)\n",
        "            if res_block == 0:\n",
        "                # linear projection residual shortcut connection to match\n",
        "                # changed dims\n",
        "                x = resnet_layer(inputs=x,\n",
        "                                 num_filters=num_filters_out,\n",
        "                                 kernel_size=1,\n",
        "                                 strides=strides,\n",
        "                                 activation=None,\n",
        "                                 batch_normalization=False)\n",
        "            x = tf.keras.layers.add([x, y])\n",
        "\n",
        "        num_filters_in = num_filters_out\n",
        "\n",
        "    # Add classifier on top.\n",
        "    # v2 has BN-ReLU before Pooling\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = AveragePooling2D(pool_size=8)(x)\n",
        "    y = Flatten()(x)\n",
        "    outputs = Dense(num_classes,\n",
        "                    activation='softmax',\n",
        "                    kernel_initializer='he_normal')(y)\n",
        "\n",
        "    # Instantiate model.\n",
        "    model = Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "    model.compile(loss='sparse_categorical_crossentropy',\n",
        "                  optimizer=tf.keras.optimizers.Adam(lr=hparams.learning_rate),\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BfGrJgWdVVg3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Fit the classifier\n"
      ]
    },
    {
      "metadata": {
        "id": "zxfLg369ZTKo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "In the below code, we first load the training, validation, and testing data. Then we define a Keras ImageDataGenerator which performs on-the-fly augmentation of the training images in order to increase the number of training samples and thus reduces the risk of overfitting the training data set.\n",
        "\n",
        "The actual classifier training happens in line 46 with the command `resnet_model.fit_generator(...)`."
      ]
    },
    {
      "metadata": {
        "id": "VQWJ-urr99OC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tf.logging.set_verbosity(tf.logging.DEBUG)\n",
        "\n",
        "resnet_model = resnet_v2((32, 32, 3), depth=56, num_classes=hparams.n_classes)\n",
        "\n",
        "\n",
        "# Download and extract CIFAR-10 data\n",
        "maybe_download_and_extract()\n",
        "\n",
        "# training data\n",
        "x_train, y_train = load_training_data()\n",
        "\n",
        "# Validation data\n",
        "x_val, y_val = load_validation_data()\n",
        "\n",
        "# Testing data\n",
        "x_test, y_test = load_testing_data()\n",
        "\n",
        "# Define callbacks\n",
        "callbacks = [\n",
        "  tf.keras.callbacks.TensorBoard(log_dir=hparams.checkpoint_dir)\n",
        "]\n",
        "\n",
        "# This will do preprocessing and realtime data augmentation:\n",
        "datagen = ImageDataGenerator(\n",
        "    featurewise_center=False,  # set input mean to 0 over the dataset\n",
        "    samplewise_center=False,  # set each sample mean to 0\n",
        "    featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
        "    samplewise_std_normalization=False,  # divide each input by its std\n",
        "    zca_whitening=False,  # apply ZCA whitening\n",
        "    zca_epsilon=1e-06,  # epsilon for ZCA whitening\n",
        "    rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
        "    # randomly shift images horizontally (fraction of total width)\n",
        "    width_shift_range=0.1,\n",
        "    # randomly shift images vertically (fraction of total height)\n",
        "    height_shift_range=0.1,\n",
        "    # set mode for filling points outside the input boundaries\n",
        "    fill_mode='nearest',\n",
        "    cval=0.,  # value used for fill_mode = \"constant\"\n",
        "    horizontal_flip=True,  # randomly flip images\n",
        "    vertical_flip=False)\n",
        "\n",
        "# Compute quantities required for feature-wise normalization\n",
        "# (std, mean, and principal components if ZCA whitening is applied).\n",
        "datagen.fit(x_train)\n",
        "\n",
        "# Fit the model on the batches generated by datagen.flow().\n",
        "resnet_model.fit_generator(\n",
        "    datagen.flow(x_train, y_train,batch_size=hparams.train_batch_size),\n",
        "    epochs=hparams.n_epochs,\n",
        "    validation_data=(x_val, y_val),\n",
        "    workers=4,\n",
        "    callbacks=callbacks)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QG-vhJ14RkBy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Visualization of confusion matrix\n",
        "\n",
        "The below code takes a confusion matrix and produces a nice and shiny visualization"
      ]
    },
    {
      "metadata": {
        "id": "UiKRYOWPfhJs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def plot_confusion_matrix(cm, classes,\n",
        "                          normalize=False,\n",
        "                          title='Confusion matrix',\n",
        "                          cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "\n",
        "    print(cm)\n",
        "\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    fmt = '.2f' if normalize else 'd'\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, format(cm[i, j], fmt),\n",
        "                 horizontalalignment=\"center\",\n",
        "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')\n",
        "    plt.tight_layout()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BqY-vngiRoTZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "results = resnet_model.predict(x_test, batch_size=hparams.test_batch_size)\n",
        "\n",
        "# convert from class probabilities to actual class predictions\n",
        "predicted_classes = np.argmax(results, axis=1)\n",
        "\n",
        "# Names of predicted classes\n",
        "class_names = [\"airplane\", \"automobile\", \"bird\", \"cat\", \"deer\", \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"]\n",
        "\n",
        "# Generate the confusion matrix\n",
        "cnf_matrix = confusion_matrix(y_test, predicted_classes)\n",
        "\n",
        "# Plot non-normalized confusion matrix\n",
        "plt.figure()\n",
        "plot_confusion_matrix(cnf_matrix, classes=class_names,\n",
        "                      title='Confusion matrix, without normalization')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}